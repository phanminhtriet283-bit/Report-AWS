---
title: "Event 2"
weight: 1
chapter: false
pre: " <b> 4.2. </b> "
---

# Summary Report “AWS Cloud Mastery Series #1”

### Event Objectives

- Update the AI/ML landscape in Vietnam and the region
- Equip attendees with AWS AI/ML foundations, with a focus on SageMaker
- Demonstrate Generative AI on Amazon Bedrock through illustrative demos
- Strengthen community connections and share practical implementation stories

### Speakers

- **Lam Tuan Kiet** — Sr. DevOps Engineer, FPT Software
- **Danh Hoang Hieu Nghi** — AI Engineer, Renova Cloud
- **Dinh Le Hoang Anh** — Cloud Engineer Trainee, First Cloud AI Journey

### Key Highlights

#### AI/ML Services Landscape on AWS

- Overview of AWS’s AI/ML services and common use cases
- SageMaker as a full lifecycle ML platform: from data ingest to inference
- Reference workflow: data cleansing, training, evaluation, packaging, and deployment
- Practical MLOps: automate pipelines, monitor, and govern model lifecycles
- Demo with SageMaker Studio covering frequent scenarios

#### Generative AI with Amazon Bedrock

- Foundation Models (Claude, Llama, Titan) and task‑aligned selection criteria
- Prompt Engineering & Chain‑of‑Thought: structuring prompts to improve answers
- RAG: combining knowledge retrieval with FMs for accuracy and freshness
- Bedrock Agents: orchestrate multi‑step workflows, tools, and enterprise data
- Guardrails: control content, reduce bias, and mitigate data‑leak risks
- Demo building a context‑aware GenAI chatbot using internal documents

### What I Learned

#### Grasping and Applying AWS AI/ML Services

- End‑to‑end model building on SageMaker: prepare data, train, and deploy
- Apply MLOps to optimize time/cost and automate key ML stages
- Translate knowledge into action through SageMaker Studio demos

#### Applying GenAI with Amazon Bedrock

- Choose the right FM (Claude, Llama, Titan) based on business needs
- Use Prompt Engineering and RAG to improve quality and reliability
- Build chatbots with guardrails and coordinate tasks via Bedrock Agents

### Applying to Work

- Automate and optimize data‑to‑model workflows
  - Use SageMaker + MLOps to shorten development, training, and deployment

- Build internal Generative AI applications
  - Combine Bedrock, RAG, and Prompt Engineering for customer support bots, employee assistants, and document‑driven Q&A

- Boost productivity and decision‑making with AI
  - Leverage FMs for faster analysis, report generation, NLP, and support for business/tech teams

### Event Experience

Attending **“AWS Cloud Mastery Series #1”** offered a clear, hands‑on, and inspiring learning journey: we updated knowledge in AI/ML and GenAI, watched real demos, engaged with experts, and explored how to bring these capabilities into day‑to‑day work. Highlights:

#### Hands‑on Content, Easy to Implement

- Clear delivery with examples and live demos made concepts easy to grasp
- Materials/guides helped map learning directly to concrete use cases

#### Energetic Learning, Broad Connections

- Direct interaction with speakers/experts through open Q&A
- Effective networking expanded ties across the AI/ML community

#### Lessons learned

- AI/ML and GenAI are increasingly accessible via platforms like SageMaker and Bedrock, accelerating experimentation and delivery
- Prompt Engineering and RAG are pivotal, determining output quality and reliability
- Real value comes when technology is designed around business goals, not isolated from context

